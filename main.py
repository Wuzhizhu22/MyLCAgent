"""
ä¼˜åŒ–åçš„ main.py - ä½¿ç”¨ LangChain æ¶ˆæ¯å¯¹è±¡
"""

import yaml
import argparse

from langchain.agents import create_agent
from langchain.tools import tool, ToolRuntime
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.config import get_stream_writer
from langchain_core.callbacks import UsageMetadataCallbackHandler
from langchain.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from dataclasses import dataclass
from typing import Optional
import uuid

# ä½¿ç”¨ SystemMessage å¯¹è±¡ä»£æ›¿å­—ç¬¦ä¸²
SYSTEM_MESSAGE = SystemMessage(
    content="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¤©æ°”é¢„æŠ¥å‘˜ï¼Œè¯´è¯æ—¶å–œæ¬¢ç”¨åŒå…³è¯­ã€‚

ä½ å¯ä»¥ä½¿ç”¨ä¸¤ä¸ªå·¥å…·ï¼š

- get_weather_for_locationï¼šä½¿ç”¨æ­¤å·¥å…·è·å–ç‰¹å®šä½ç½®çš„å¤©æ°”
- get_user_locationï¼šä½¿ç”¨æ­¤å·¥å…·è·å–ç”¨æˆ·çš„ä½ç½®

å¦‚æœç”¨æˆ·å‘ä½ è¯¢é—®å¤©æ°”ï¼Œç¡®ä¿ä½ çŸ¥é“ä½ç½®ã€‚å¦‚æœä»é—®é¢˜ä¸­å¯ä»¥çœ‹å‡ºä»–ä»¬æŒ‡çš„æ˜¯ä»–ä»¬æ‰€åœ¨çš„ä½ç½®ï¼Œè¯·ä½¿ç”¨get_user_locationå·¥å…·æŸ¥æ‰¾ä»–ä»¬çš„ä½ç½®ã€‚""",
    id="system_001",  # å¦‚æœæœªæ¥æ·»åŠ å¤šç³»ç»Ÿæç¤ºåˆ‡æ¢ç­‰åŠŸèƒ½å¯ç”¨
)


@dataclass
class Context:
    """è‡ªå®šä¹‰è¿è¡Œæ—¶ä¸Šä¸‹æ–‡æ¨¡å¼ã€‚"""

    user_id: str


@tool
def get_weather_for_location(city: str) -> str:
    """è·å–ç»™å®šåŸå¸‚çš„å¤©æ°”ã€‚"""
    writer = get_stream_writer()
    writer(f"ğŸ” æ­£åœ¨æŸ¥è¯¢åŸå¸‚: {city}")
    writer(f"ğŸ“Š è·å–åˆ°åŸå¸‚æ•°æ®: {city}")
    return f"{city}æ€»æ˜¯é˜³å…‰æ˜åªšï¼"


@tool
def get_user_location(runtime: ToolRuntime[Context]) -> str:
    """æ ¹æ®ç”¨æˆ·IDæ£€ç´¢ç”¨æˆ·ä¿¡æ¯ã€‚"""
    writer = get_stream_writer()
    user_id = runtime.context.user_id
    writer(f"ğŸ‘¤ æ­£åœ¨æŸ¥æ‰¾ç”¨æˆ·ID: {user_id}")
    location = "ä½›ç½—é‡Œè¾¾" if user_id == "1" else "æ—§é‡‘å±±"
    writer(f"ğŸ“ æ‰¾åˆ°ç”¨æˆ·ä½ç½®: {location}")
    return location


# å®šä¹‰å“åº”æ¨¡å¼
@dataclass
class ResponseFormat:
    punny_response: str
    weather_conditions: str | None = None

    def __str__(self):
        result = f"å›ç­”ï¼š{self.punny_response}"
        if self.weather_conditions:
            result += f"\nå¤©æ°”çŠ¶å†µï¼š{self.weather_conditions}"
        return result


# ä»llm.yamlåŠ è½½é…ç½®
def load_config(config_path):
    """ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®"""
    with open(config_path, "r") as f:
        return yaml.safe_load(f)


def create_human_message(content: str, user_id: str = None) -> HumanMessage:
    """åˆ›å»ºå¸¦å…ƒæ•°æ®çš„äººç±»æ¶ˆæ¯"""
    return HumanMessage(
        content=content, name=f"user_{user_id}" if user_id else "user", id=f"msg_{uuid.uuid4().hex[:8]}"
    )


def process_message_blocks(message: AIMessage) -> dict:
    """å¤„ç† AIMessage çš„ content_blocksï¼Œæå–ä¸åŒç±»å‹çš„å†…å®¹"""
    result = {"tool_calls": [], "text_content": [], "reasoning": None}

    # ç›´æ¥è®¿é—® content_blocksï¼ˆä¸éœ€è¦ getattrï¼‰
    content_blocks = message.content_blocks

    if content_blocks:
        for block in content_blocks:
            block_type = block.get("type")

            if block_type == "tool_call":
                result["tool_calls"].append(
                    {"name": block.get("name"), "args": block.get("args"), "id": block.get("id")}
                )
            elif block_type == "text":
                result["text_content"].append(block.get("text"))
            elif block_type == "reasoning":
                # æ”¯æŒæ¨ç†è¿‡ç¨‹ï¼ˆå¦‚ OpenAI o1 æ¨¡å‹ï¼‰
                result["reasoning"] = block.get("summary", [])

    return result


tool_config = load_config("./llm.yaml")
model = ChatOpenAI(**tool_config["llm"])


def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="å¤©æ°”æŸ¥è¯¢æ™ºèƒ½ä½“")
    parser.add_argument(
        "--mode",
        type=str,
        choices=["stream", "invoke"],
        default="invoke",
        help="è¿è¡Œæ¨¡å¼ï¼šstreamï¼ˆæµå¼è¾“å‡ºï¼‰æˆ– invokeï¼ˆä¸€æ¬¡æ€§è¾“å‡ºï¼‰",
    )
    args = parser.parse_args()

    checkpointer = InMemorySaver()
    agent = create_agent(
        model=model,
        system_prompt=SYSTEM_MESSAGE.content,  # ä» SystemMessage æå–å†…å®¹
        tools=[get_user_location, get_weather_for_location],
        context_schema=Context,
        response_format=ResponseFormat,
        checkpointer=checkpointer,
    )

    # åˆ›å»º usage metadata callback handler
    callback = UsageMetadataCallbackHandler()
    config_with_callback = {"configurable": {"thread_id": "1"}, "callbacks": [callback]}

    # ä½¿ç”¨ HumanMessage å¯¹è±¡
    user_message = create_human_message("å¤©æ°”å¦‚ä½•å‘¢?", user_id="1")

    if args.mode == "stream":
        # æµå¼è¾“å‡ºæ¨¡å¼
        print("=== å¼€å§‹æµå¼è¾“å‡º ===\n")

        for stream_mode, chunk in agent.stream(
            {"messages": [user_message]},
            stream_mode=["updates", "custom"],
            config=config_with_callback,
            context=Context(user_id="1"),
        ):
            print(f"ğŸ“¡ æµæ¨¡å¼: {stream_mode}")

            if stream_mode == "custom":
                print(f"  ğŸ¯ {chunk}")
            elif stream_mode == "updates":
                for step, data in chunk.items():
                    print(f"ğŸ“ æ­¥éª¤: {step}")

                    messages = data.get("messages", [])
                    if messages:
                        last_message = messages[-1]

                        # ä½¿ç”¨ä¼˜åŒ–çš„æ¶ˆæ¯å¤„ç†å‡½æ•°
                        if isinstance(last_message, AIMessage):
                            blocks = process_message_blocks(last_message)

                            # æ˜¾ç¤ºå·¥å…·è°ƒç”¨
                            for tool_call in blocks["tool_calls"]:
                                print(f"  ğŸ› ï¸  è°ƒç”¨å·¥å…·: {tool_call['name']}")
                                print(f"  ğŸ“ å‚æ•°: {tool_call['args']}")

                            # æ˜¾ç¤ºæ–‡æœ¬å†…å®¹
                            for text in blocks["text_content"]:
                                print(f"  ğŸ’¬ å†…å®¹: {text}")

                            # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
                            if blocks["reasoning"]:
                                print(f"  ğŸ§  æ¨ç†è¿‡ç¨‹:")
                                for summary in blocks["reasoning"]:
                                    print(f"    - {summary.get('text', '')}")
                        else:
                            # å…¶ä»–ç±»å‹çš„æ¶ˆæ¯
                            print(f"  ğŸ“„ æ¶ˆæ¯ç±»å‹: {type(last_message).__name__}")
                            print(f"  ğŸ“„ æ¶ˆæ¯å†…å®¹: {last_message.content}")

                    print()

        print("\n=== æµå¼è¾“å‡ºå®Œæˆ ===")
    else:
        # invoke æ¨¡å¼
        print("=== ä½¿ç”¨ invoke æ¨¡å¼ ===\n")

        result = agent.invoke(
            {"messages": [user_message]},
            config=config_with_callback,
            context=Context(user_id="1"),
        )

        print(result["structured_response"])
        print("\n=== invoke å®Œæˆ ===")

    # æ‰“å° Token ä½¿ç”¨ç»Ÿè®¡
    print("\nğŸ“Š Token ä½¿ç”¨ç»Ÿè®¡:")
    if callback.usage_metadata:
        for model_name, metadata in callback.usage_metadata.items():
            print(f"  æ¨¡å‹: {model_name}")
            print(f"    è¾“å…¥ Tokens: {metadata.get('input_tokens', 0)}")
            print(f"    è¾“å‡º Tokens: {metadata.get('output_tokens', 0)}")
            print(f"    æ€»è®¡ Tokens: {metadata.get('total_tokens', 0)}")
    else:
        print("  æœªè·å–åˆ° token ä½¿ç”¨ç»Ÿè®¡")
    # print(f"  å®Œæ•´ metadata: {callback.usage_metadata}")


if __name__ == "__main__":
    main()
